---
bg: "coli.jpg"
layout: post
mathjax: true
title:  "2.2 - Multiplying Matrices and Vectors"
crawlertitle: "2.2 - Multiplying Matrices and Vectors"
summary: "Multiplying Matrices and Vectors"
date:   2018-02-01 20:09:47 +0700
categories: posts
tags: ['linear-algebra', 'python', 'numpy', 'deep-learning-book']
author: hadrien
jupyter: https://github.com/hadrienj/deepLearningBook-Notes/blob/master/2.2%20Multiplying%20Matrices%20and%20Vectors.ipynb
---

The matrix product is the sum of the rows of the first matrix and the columns of the second one. Thus, if the shape of the first matrix is ($m \times n$) the second matrix need to be of shape ($n \times x$).

### Example 1.

$\boldsymbol{A} _{3,2} \times \boldsymbol{B} _{2, 1} = \boldsymbol{C} _{3, 1}$

$
\begin{bmatrix}
    A_{1,1} & A_{1,2} \\\
    A_{2,1} & A_{2,2} \\\
    A_{3,1} & A_{3,2}
\end{bmatrix}\times
\begin{bmatrix}
    B_{1,1} \\\
    B_{2,1}
\end{bmatrix}=
\begin{bmatrix}
    A_{1,1} \times B_{1,1} + A_{1,2} \times B_{2,1} \\\
    A_{2,1} \times B_{1,1} + A_{2,2} \times B_{2,1} \\\
    A_{3,1} \times B_{1,1} + A_{3,2} \times B_{2,1}
\end{bmatrix}
$


```python
A = np.array([[1, 2], [3, 4], [5, 6]])
print("A.shape: %s\n\n%s" %(A.shape, A))
```

    A.shape: (3, 2)
    
    [[1 2]
     [3 4]
     [5 6]]



```python
B = np.array([[2], [4]])
print("B.shape: %s\n\n%s" %(B.shape, B))
```

    B.shape: (2, 1)
    
    [[2]
     [4]]


#### The numpy command 'dot' can be used to compute the matrix (or dot) product


```python
C = np.dot(A, B)
print("C.shape: %s\n\n%s" %(C.shape, C))
```

    C.shape: (3, 1)
    
    [[10]
     [22]
     [34]]


### Example 2.

$\boldsymbol{A} _{4,3} \times \boldsymbol{B} _{3, 2} = \boldsymbol{C} _{4, 2}$

$
\begin{align\*}
&\begin{bmatrix}
    A_{1,1} & A_{1,2} & A_{1,3} \\\
    A_{2,1} & A_{2,2} & A_{2,3} \\\
    A_{3,1} & A_{3,2} & A_{3,3} \\\
    A_{4,1} & A_{4,2} & A_{4,3}
\end{bmatrix}\times
\begin{bmatrix}
    B_{1,1} & B_{1,2} \\\
    B_{2,1} & B_{2,2} \\\
    B_{3,1} & B_{3,2}\\\
\end{bmatrix}\\\
&=
\begin{bmatrix}
    A_{1,1} \times B_{1,1} + A_{1,2} \times B_{2,1} + A_{1,3} \times B_{3,1} & A_{1,1} \times B_{1,2} + A_{1,2} \times B_{2,2} + A_{1,3} \times B_{3,2} \\\
    A_{2,1} \times B_{1,1} + A_{2,2} \times B_{2,1} + A_{2,3} \times B_{3,1} & A_{2,1} \times B_{1,2} + A_{2,2} \times B_{2,2} + A_{2,3} \times B_{3,2} \\\
    A_{3,1} \times B_{1,1} + A_{3,2} \times B_{2,1} + A_{3,3} \times B_{3,1} & A_{3,1} \times B_{1,2} + A_{3,2} \times B_{2,2} + A_{3,3} \times B_{3,2} \\\
    A_{4,1} \times B_{1,1} + A_{4,2} \times B_{2,1} + A_{4,3} \times B_{3,1} & A_{4,1} \times B_{1,2} + A_{4,2} \times B_{2,2} + A_{4,3} \times B_{3,2} \\\
\end{bmatrix}
\end{align\*}
$


```python
A = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]])
print("A.shape: %s\n\n%s" %(A.shape, A))
```

    A.shape: (4, 3)
    
    [[ 1  2  3]
     [ 4  5  6]
     [ 7  8  9]
     [10 11 12]]



```python
B = np.array([[2, 7], [1, 2], [3, 6]])
print("B.shape: %s\n\n%s" %(B.shape, B))
```

    B.shape: (3, 2)
    
    [[2 7]
     [1 2]
     [3 6]]



```python
C = np.dot(A, B)
print("C.shape: %s\n\n%s" %(C.shape, C))
```

    C.shape: (4, 2)
    
    [[ 13  29]
     [ 31  74]
     [ 49 119]
     [ 67 164]]


#### So the dot product can be formalized like that:

$
C_{i,j} = A_{i,k}B_{k,j} = \sum_{k}A_{i,k}B_{k,i}
$

More detailed examples about the dot product can be found [here](https://www.mathsisfun.com/algebra/matrix-multiplying.html).

# Matrices mutliplication is distributive

$\boldsymbol{A}(\boldsymbol{B}+\boldsymbol{C}) = \boldsymbol{AB}+\boldsymbol{AC}$

### Example 3.

$
\boldsymbol{A}=\begin{bmatrix}
    2 & 3 \\\
    1 & 4 \\\
    7 & 6
\end{bmatrix}, 
\boldsymbol{B}=\begin{bmatrix}
    5 \\\
    2
\end{bmatrix}, 
\boldsymbol{C}=\begin{bmatrix}
    4 \\\
    3
\end{bmatrix}
$


$
\begin{align\*}
\boldsymbol{A}(\boldsymbol{B}+\boldsymbol{C})&=\begin{bmatrix}
    2 & 3 \\\
    1 & 4 \\\
    7 & 6
\end{bmatrix}\times
\left(\begin{bmatrix}
    5 \\\
    2
\end{bmatrix}+
\begin{bmatrix}
    4 \\\
    3
\end{bmatrix}\right)\\\
&=
\begin{bmatrix}
    2 & 3 \\\
    1 & 4 \\\
    7 & 6
\end{bmatrix}\times
\begin{bmatrix}
    9 \\\
    5
\end{bmatrix}\\\
&=
\begin{bmatrix}
    2 \times 9 + 3 \times 5 \\\
    1 \times 9 + 4 \times 5 \\\
    7 \times 9 + 6 \times 5
\end{bmatrix}\\\
&=
\begin{bmatrix}
    33 \\\
    29 \\\
    93
\end{bmatrix}
\end{align\*}
$

is equivalent to

$
\begin{align\*}
\boldsymbol{A}\boldsymbol{B}+\boldsymbol{A}\boldsymbol{C}
&=\begin{bmatrix}
    2 & 3 \\\
    1 & 4 \\\
    7 & 6
\end{bmatrix}\times
\begin{bmatrix}
    5 \\\
    2
\end{bmatrix}+
\begin{bmatrix}
    2 & 3 \\\
    1 & 4 \\\
    7 & 6
\end{bmatrix}\times
\begin{bmatrix}
    4 \\\
    3
\end{bmatrix}\\\
&=
\begin{bmatrix}
    2 \times 5 + 3 \times 2 \\\
    1 \times 5 + 4 \times 2 \\\
    7 \times 5 + 6 \times 2
\end{bmatrix}+
\begin{bmatrix}
    2 \times 4 + 3 \times 3 \\\
    1 \times 4 + 4 \times 3 \\\
    7 \times 4 + 6 \times 3
\end{bmatrix}\\\
&=
\begin{bmatrix}
    16 \\\
    13 \\\
    47
\end{bmatrix}+
\begin{bmatrix}
    17 \\\
    16 \\\
    46
\end{bmatrix}\\\
&=
\begin{bmatrix}
    33 \\\
    29 \\\
    93
\end{bmatrix}
\end{align\*}
$


```python
A = np.array([[2, 3], [1, 4], [7, 6]])
print("A.shape: %s\n\n%s" %(A.shape, A))
B = np.array([[5], [2]])
print("\nB.shape: %s\n\n%s" %(B.shape, B))
```

    A.shape: (3, 2)
    
    [[2 3]
     [1 4]
     [7 6]]
    
    B.shape: (2, 1)
    
    [[5]
     [2]]



```python
C = np.array([[4], [3]])
print("C.shape: %s\n\n%s" %(C.shape, C))
```

    C.shape: (2, 1)
    
    [[4]
     [3]]



```python
# A(B + C)
D = np.dot(A, (B+C))
print("D.shape: %s\n\n%s" %(D.shape, D))
```

    D.shape: (3, 1)
    
    [[33]
     [29]
     [93]]



```python
# AB + AC
D = np.dot(A, B) + np.dot(A, C)
print("D.shape: %s\n\n%s" %(D.shape, D))
```

    D.shape: (3, 1)
    
    [[33]
     [29]
     [93]]


# Matrices mutliplication is associative

$\boldsymbol{A}(\boldsymbol{BC}) = \boldsymbol{AB}(\boldsymbol{C})$



```python
A = np.array([[2, 3], [1, 4], [7, 6]])
print("A.shape: %s\n\n%s" %(A.shape, A))
B = np.array([[5, 3], [2, 2]])
print("\nB.shape: %s\n\n%s" %(B.shape, B))
```

    A.shape: (3, 2)
    
    [[2 3]
     [1 4]
     [7 6]]
    
    B.shape: (2, 2)
    
    [[5 3]
     [2 2]]



```python
# A(BC)
D = np.dot(A, np.dot(B, C))
print("D.shape: %s\n\n%s" %(D.shape, D))
```

    D.shape: (3, 1)
    
    [[100]
     [ 85]
     [287]]



```python
# AB(C)
D = np.dot(np.dot(A, B), C)
print("D.shape: %s\n\n%s" %(D.shape, D))
```

    D.shape: (3, 1)
    
    [[100]
     [ 85]
     [287]]


# Matrix multiplication is not commutative

$\boldsymbol{AB} \neq \boldsymbol{BA}$


```python
A = np.array([[2, 3], [6, 5]])
print("\nA.shape: %s\n\n%s" %(A.shape, A))

B = np.array([[5, 3], [2, 2]])
print("\nB.shape: %s\n\n%s" %(B.shape, B))
```

    
    A.shape: (2, 2)
    
    [[2 3]
     [6 5]]
    
    B.shape: (2, 2)
    
    [[5 3]
     [2 2]]



```python
AB = np.dot(A, B)
print("AB.shape: %s\n\n%s" %(AB.shape, AB))
```

    AB.shape: (2, 2)
    
    [[16 12]
     [40 28]]



```python
BA = np.dot(B, A)
print("BA.shape: %s\n\n%s" %(BA.shape, BA))
```

    BA.shape: (2, 2)
    
    [[28 30]
     [16 16]]


## However vector multiplication is commutative

$x^{ \text{T}}y = y^{\text{T}}x $


```python
x = np.array([[2], [6]])
print("\nx.shape: %s\n\n%s" %(x.shape, x))

y = np.array([[5], [2]])
print("\ny.shape: %s\n\n%s" %(y.shape, y))
```

    
    x.shape: (2, 1)
    
    [[2]
     [6]]
    
    y.shape: (2, 1)
    
    [[5]
     [2]]



```python
x_ty = np.dot(x.T, y)
print("x_ty.shape: %s\n\n%s" %(x_ty.shape, x_ty))
```

    x_ty.shape: (1, 1)
    
    [[22]]



```python
y_tx = np.dot(y.T, x)
print("y_tx.shape: %s\n\n%s" %(y_tx.shape, y_tx))
```

    y_tx.shape: (1, 1)
    
    [[22]]


## Simplification of the matrix product

$(AB)^{\text{T}} = B^{\text{T}}A^{\text{T}}$


```python
A = np.array([[2, 3], [1, 4], [7, 6]])
print("A.shape: %s\n\n%s" %(A.shape, A))
B = np.array([[5, 3], [2, 2]])
print("\nB.shape: %s\n\n%s" %(B.shape, B))
```

    A.shape: (3, 2)
    
    [[2 3]
     [1 4]
     [7 6]]
    
    B.shape: (2, 2)
    
    [[5 3]
     [2 2]]


$(AB)^{\text{T}}$:


```python
AB_t = np.dot(A, B).T
print("AB_t.shape: %s\n\n%s" %(AB_t.shape, AB_t))
```

    AB_t.shape: (2, 3)
    
    [[16 13 47]
     [12 11 33]]


$B^{\text{T}}A^{\text{T}}$:


```python
B_tA = np.dot(B.T, A.T)
print("B_tA.shape: %s\n\n%s" %(B_tA.shape, B_tA))
```

    B_tA.shape: (2, 3)
    
    [[16 13 47]
     [12 11 33]]


# System of linear equations

Matrices can be used to describe a system of linear equations of the form $\boldsymbol{Ax}=\boldsymbol{b}$. Here is a set of linear equations:

$
A_{1,1}x_1 + A_{1,2}x_2 + A_{1,n}x_n = b_1 \\\
A_{2,1}x_1 + A_{2,2}x_2 + A_{2,n}x_n = b_2 \\\
\cdots \\\
A_{m,1}x_1 + A_{m,2}x_2 + A_{m,n}x_n = b_n
$

The left hand term can considered as the product of a matrix **A** containing weights for each variable ($n$ columns) and each equation ($m$ rows)

$
\begin{bmatrix}
    A_{1,1} & A_{1,2} & \cdots & A_{1,n} \\\
    A_{2,1} & A_{2,2} & \cdots & A_{2,n} \\\
    \cdots & \cdots & \cdots & \cdots \\\
    A_{m,1} & A_{m,2} & \cdots & A_{m,n}
\end{bmatrix}
$

with a vector **x** containing the $n$ variables

$
\begin{bmatrix}
    x_1 \\\
    x_2 \\\
    \cdots \\\
    x_n
\end{bmatrix}
$

The equation system can be wrote like that

$
\begin{bmatrix}
    A_{1,1} & A_{1,2} & \cdots & A_{1,n} \\\
    A_{2,1} & A_{2,2} & \cdots & A_{2,n} \\\
    \cdots & \cdots & \cdots & \cdots \\\
    A_{m,1} & A_{m,2} & \cdots & A_{m,n}
\end{bmatrix}
\times
\begin{bmatrix}
    x_1 \\\
    x_2 \\\
    \cdots \\\
    x_n
\end{bmatrix}
=
\begin{bmatrix}
    b_1 \\\
    b_2 \\\
    \cdots \\\
    b_m
\end{bmatrix}
$

Or simply $\boldsymbol{Ax}=\boldsymbol{b}$.

### Example 4.

The common form of a linear equation ($y=ax+b$) can be converted to the matrix form. In this example, we'll use the variable name $w$ instead of $x$ to avoid confusion with our vector **x** that contain the variables.

$
\begin{align\*}
&y=2w+1\\\
\Leftrightarrow& 2w-y=-1
\end{align\*}
$

In this example, the system of equations contains only 1 equation (1 row: $m=1$) and 2 variables (2 columns: $n=2$). It is the same thing as $A_{1,1}x_1 + A_{1,2}x_2 + A_{1,n}x_n = b_1$ with 

- $A_{1,1}$ is 2
- $x_1$ is the variable $w$
- $A_{1,2}$ is -1
- $x_2$ is the variable $y$
- $b$ is -1

This equation can be wrote under the matrix form. **A** will be the matrix of dimension $m\times n$ containing scalars multiplying these variables (here $w$ is multiplied by 2 and $y$ by -1). The vector **x** contains the variables $w$ and $y$. And the right hand term is the constant **b**:

$
A=
\begin{bmatrix}
    2 & -1
\end{bmatrix}
$

$
x=
\begin{bmatrix}
    w\\\
    y
\end{bmatrix}
$

$
b=
\begin{bmatrix}
    -1
\end{bmatrix}
$

The matrix product between **A** and **x** gives us the right left hand side of the equation:

$
\begin{align\*}
Ax&=
\begin{bmatrix}
    2 & -1
\end{bmatrix}
\begin{bmatrix}
    y\\\
    z
\end{bmatrix}\\\
&=
2w - y\\\
b &= -1\\\
\Leftrightarrow
&2w - y = -1
\end{align\*}
$

